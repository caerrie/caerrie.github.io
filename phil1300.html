<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>phil1300</title>
    <link href="style.css" rel="stylesheet" type="text/css" media="all">
    
    <style>
    p{
      margin-top: 0px; 
      margin-bottom: 10px;
    }

    h1{
      font-family: 'Merriweather', serif;
      font-weight: 800;
      letter-spacing: 0;
    }

    h2{
      font-size: 14px;
      font-weight: normal;
    }

    img{
      width: 650px;
    }

    #container{
      background: rgb(255, 255, 255);
      margin-left: auto;
      margin-right: auto;
      margin-top: 50px;
      margin-bottom: 100px;
      width: 650px;
      /* height: 100%; */
    }
    </style>
  </head>
  
  <body>
    <div id="container">
        <h1 style="margin-bottom: 15px">Generative AI and It’s Challenge to Acquiring Knowledge</h1>
        <p style="font-size:14px">Carrie Wang <span style="color:#aaa; margin-left: 10px">Dec 5, 2022</span></p>
        <br>
        <p>
          Image manipulation isn’t new and with tools like Photoshop, it has become accessible to any individual with a computer. With the proper skills, Photoshop can alter an image rather realistically. Digitally manipulating images has been so widely spread that the internet adopted the term “photoshopped” to describe them. Used the wrong way, image alteration can be frowned upon, but for the most part, it’s become a normalized and integrated part of the internet. 
          <br><br>
          On the other hand, people have not been as receptive to artificial intelligence learning to alter images. With a push of a few buttons, any individual is able to generate a unique image with no skills required. These tools can manipulate or create realistic images including original artworks and faces of people who never existed. This opens the gateway to fake news and disinformation. 
          <br><br>
          <img src="https://media.wired.com/photos/6378127aef69bd3269392c21/master/pass/business-ai-code-art-copyright-113493446.jpg">
          <br><br>
          Altering of a person in a recording or image using artificial intelligence, known as a deepfake, is not always created with the intention of disinformation - like the deepfake Tom Cruise videos on TikTok. However, when widely spread and taken out of context, it can be taken the wrong way. Deepfake videos of politicians saying and doing things that they never said or done create skepticism and doubt among voters. The increase of false information then leads people to be more suspicious of the opposing side, further driving them to remain in their bubble and widening the polarization. 
          <br><br>
          Since these generative AI tools can produce disinformative and graphic content, is it the developer's responsibility to filter them out? Or does it rely on the user’s ethics to follow the terms of use? One AI image generator called DALL-E has taken upon filtering so that any violence or misuse of their tool will not be permitted. 
          <br><br>
          Other issues arise with deepfakes, such as the question of privacy and consent. While there are drawbacks to this new tool, certain industries have found productive purposes for it. AI’s ability to generate unique ideas is inspiring for designers and architects as it saves time and cost, but are the benefits able to outweigh the downsides? 
          <br><br>
          While both Photoshop and generative AI falsify images, Photoshop isn’t troublesome, so why does the rise of AI appear as a threat to acquiring knowledge? With the proper education and tools to detect altered content online, would generative AI remain an epistemic issue or would the costs outweigh them?
        </p>
        <br><br>
        <h2>
          References:
          <br>
          https://venturebeat.com/ai/the-future-of-generative-ai-and-its-ethical-implications/
          <br>
          https://www.linkedin.com/pulse/implications-growth-ai-generated-images-arek-skuza
          <br>
          https://www.forbes.com/sites/lutzfinger/2022/09/08/deepfakesthe-danger-of-artificial-intelligence-that-we-will-learn-to-manage-better/?sh=58d8c5cd163a
          <br>
          https://www.brookings.edu/research/is-seeing-still-believing-the-deepfake-challenge-to-truth-in-politics/
        </h2>
    </div>
  </body>
</html>

